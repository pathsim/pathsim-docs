{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply PathSim docs matplotlib style for consistent, theme-friendly figures\n",
    "plt.style.use('../pathsim_docs.mplstyle')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Automatic Differentiation\n",
    "==========================\n",
    "\n",
    "PathSim has an integrated framework for automatic differentiation (forward mode AD) within the :mod:`.optim` module. It mainly consists of the :class:`.Value` class that implements arithmetic operations and numpy ufuncs via operator overloading to propagate gradients through a computational graph.\n",
    "\n",
    "For a dynamical system simulation framework such as PathSim, this is very consequential. All the operations in the simulation loop, all solver steps, all algebraic and dynamic updates are purely algebraic on the numerics side.\n",
    "\n",
    "This means, that when the simulation loop is sufficiently robust to handle all kinds of python objects (as long as they implement the core arithmetic operations needed), they can be used instead of regular floating point numbers to advance the simulation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Value class and derivatives\n",
    "----------------------------\n",
    "\n",
    "To understand this better, lets first have a look at what the :class:`.Value` class does by comparing it to standard float operations. Lets say we have the following function that consists of multiple input arguments, and a single output that is obtained by some algebraic operations applied in some order to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(a, b, c):\n",
    "    return (a**2 - b) * np.cos(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by evaluating our function with some regular floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs are just regular floats\n",
    "x, y, z = 1.1, 3.5, 2.0\n",
    "\n",
    "w = f(x, y, z)\n",
    "\n",
    "print(w) #0.9529762556929561"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "As expected we get a float back. Next wrap the same floats into :class:`.Value` instances by using the :meth:`.Value.array` classmethod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathsim.optim import Value\n",
    "\n",
    "#inputs are Value instances\n",
    "x, y, z = Value.array([1.1, 3.5, 2.0])\n",
    "\n",
    "w = f(x, y, z)\n",
    "\n",
    "print(w) #Value(val=0.9529762556929561, grad=defaultdict(<class 'float'>, {2565427398528: np.float64(-0.9155230404037134), 2565426875648: np.float64(0.4161468365471424), 2565403265920: np.float64(2.082291107430811)}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Here the values propagate seemlessly through the operations and the final output is again of type :class:`.Value`. But this one has tracked the derivatives within the internal gradient ``dict`` alongside the actual float evaluation. The gradients can be extracted by using the :meth:`.Value.__call__` method with the value instance we want to extract the derivative of like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_dx = w(x)\n",
    "dw_dy = w(y)\n",
    "dw_dz = w(z)\n",
    "\n",
    "print(dw_dx) #-0.9155230404037134\n",
    "print(dw_dy) #0.4161468365471424\n",
    "print(dw_dz) #2.082291107430811"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Or in a more general way that also works with arrays of Value instances with the class method :meth:`.Value.der`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_dx = Value.der(w, x)\n",
    "dw_dy = Value.der(w, y)\n",
    "dw_dz = Value.der(w, z)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The main application for the :class:`.Value` class is enabling sensitivity analysis and end-to-end differentiability for PathSim simulations. Its also used for automatic linearization of operators (:meth:`.Operator.jac`), but more on that later."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Sensitivity Analysis\n",
    "--------------------\n",
    "\n",
    "Sensitivity analysis is fundamentally about understanding how changes in input parameters propagate through a dynamic system to affect its outputs. In mathematical terms, if we have a system output :math:`y = f(x, p)` that depends on state :math:`x` and parameters :math:`p`, the sensitivity :math:`S_p` with respect to parameter :math:`p` is defined as:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   S_p = \\frac{\\partial y}{\\partial p}\n",
    "\n",
    "\n",
    "For dynamical systems where states evolve according to differential equations:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   \\frac{dx}{dt} = f(x, p, t)\n",
    "\n",
    "\n",
    "The sensitivity trajectories themselves follow their own differential equations, derived by differentiating the original system equations with respect to parameters:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   \\frac{d}{dt}\\left(\\frac{\\partial x}{\\partial p}\\right) = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial p} + \\frac{\\partial f}{\\partial p}\n",
    "\n",
    "\n",
    "PathSim's automatic differentiation approach allows computing these sensitivities without explicitly deriving and solving these sensitivity equations. Instead, the gradients are propagated through the computational graph represented by the simulation steps."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Linear Feedback Sensitivities\n",
    "------------------------------\n",
    "\n",
    "Lets see how this works with a small example. A linear feedback system.\n",
    "\n",
    ".. image:: figures/figures_g/linear_feedback_blockdiagram_g.png\n",
    "   :width: 700\n",
    "   :align: center\n",
    "   :alt: block diagram of linear feedback system\n",
    "\n",
    "\n",
    "The system dynamics from the diagram above, can be represented by the first order ODE:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   \\frac{dx}{dt} = a x + s(t)\n",
    "\n",
    "\n",
    "Translating the block diagram to PathSim looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathsim import Simulation, Connection\n",
    "from pathsim.blocks import Source, Integrator, Amplifier, Adder, Scope\n",
    "\n",
    "#AD framework\n",
    "from pathsim.optim import Value\n",
    "\n",
    "#step delay\n",
    "tau = 3\n",
    "\n",
    "#parameters for AD and standard deviations (the only difference to regular simulation setup)\n",
    "a  = Value(-1, sig=0.1)\n",
    "s  = Value(1, sig=0.05)\n",
    "x0 = Value(2, sig=0.5)\n",
    "\n",
    "#step function with delay\n",
    "def step(t):\n",
    "    return s*float(t>tau)\n",
    "\n",
    "#blocks defining the system\n",
    "src = Source(step)\n",
    "itg = Integrator(x0)\n",
    "amp = Amplifier(a)\n",
    "add = Adder()\n",
    "sco = Scope(labels=[\"s(t)\", \"x(t)\"])\n",
    "\n",
    "#initialize simulation\n",
    "sim = Simulation(\n",
    "    blocks=[src, itg, amp, add, sco],\n",
    "    connections=[\n",
    "        Connection(src, add[0], sco[0]),\n",
    "        Connection(amp, add[1]),\n",
    "        Connection(add, itg),\n",
    "        Connection(itg, amp, sco[1])\n",
    "    ], dt=0.01)\n",
    "\n",
    "#run simulation for some time\n",
    "sim.run(4*tau)\n",
    "\n",
    "#plot the results\n",
    "sco.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Now, after the simulation has finished, the results that the :class:`.Scope` has recorded are not regular floats but :class:`.Value` instances that have tracked the partial derivatives through the whole system dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#get the simulation results\n",
    "time, [_, x] = sco.read()\n",
    "\n",
    "#extract the sensitivities\n",
    "dx_da = Value.der(x, a)\n",
    "dx_ds = Value.der(x, s)\n",
    "dx_dx0 = Value.der(x, x0)\n",
    "\n",
    "#plot sensitivities\n",
    "fig, ax = plt.subplots(nrows=1, figsize=(8, 4), tight_layout=True, dpi=120)\n",
    "\n",
    "ax.plot(time, dx_da, lw=2, c=\"tab:red\", label=r\"$\\partial x(t)/ \\partial a$\")\n",
    "ax.plot(time, dx_ds, lw=2, c=\"tab:green\", label=r\"$\\partial x(t)/\\partial s$\")\n",
    "ax.plot(time, dx_dx0, lw=2, c=\"tab:blue\", label=r\"$\\partial x(t)/\\partial x_0$\")\n",
    "\n",
    "ax.set_xlabel(\"time [s]\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. image:: ../figures/linear_feedback_result_sensitivities.png\n",
    "   :width: 700\n",
    "   :align: center\n",
    "   :alt: sensitivities of linear feedback system\n",
    "\n",
    "\n",
    "The sensitivities we calculated provide specific insights:\n",
    "\n",
    "1. :math:`\\frac{\\partial x}{\\partial a}` (dx_da): Shows how the feedback gain affects the system response. Negative values indicate that increasing the gain would reduce the state value at that time.\n",
    "\n",
    "2. :math:`\\frac{\\partial x}{\\partial s}` (dx_ds): Illustrates the system's sensitivity to input amplitude. This reveals how input scaling propagates through the feedback structure. For the linear system, this selects the normalized particular solution from the ODE.\n",
    "\n",
    "3. :math:`\\frac{\\partial x}{\\partial x_0}` (dx_dx0): Demonstrates how initial conditions influence the trajectory over time. In stable systems, this sensitivity typically decays, showing diminishing influence of initial conditions. For linear systems, this selects the normalized homogenous solution of the ODE."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Sensitivity Analysis and Uncertainty Quantification\n",
    "----------------------------------------------------\n",
    "\n",
    "Sensitivity analysis forms a critical bridge to uncertainty quantification. When parameters have associated uncertainties, the sensitivities allow approximating how these uncertainties propagate to the outputs.\n",
    "\n",
    "For a parameter :math:`p` with uncertainty :math:`\\sigma_p`, the corresponding contribution to output uncertainty can be approximated using a first-order Taylor expansion:\n",
    "\n",
    ".. math::\n",
    "\n",
    "   \\sigma_y^2 \\approx \\sum_i \\left(\\frac{\\partial y}{\\partial p_i}\\right)^2 \\sigma_{p_i}^2\n",
    "\n",
    "\n",
    "This is particularly valuable in engineering applications where parameters often have associated measurement or estimation uncertainties.\n",
    "\n",
    "We can extend our linear feedback example to incorporate uncertainty. The :meth:`.Value.var` staticmethod can be used to approximate the total variance of the output signal from the individual standard deviations of the parameters using the propagated partial derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract output variance at each time point\n",
    "var_x = Value.var(x, [a, s, x0])\n",
    "\n",
    "#standard deviation bounds\n",
    "x_upper = Value.numeric(x) + np.sqrt(var_x)\n",
    "x_lower = Value.numeric(x) - np.sqrt(var_x)\n",
    "\n",
    "#plot with uncertainty bounds\n",
    "time, [stp, _] = sco.read()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, figsize=(8, 4), tight_layout=True, dpi=120)\n",
    "\n",
    "ax.plot(time, stp, lw=2, c=\"tab:red\", label=\"s(t)\")\n",
    "ax.plot(time, x, lw=2, c=\"tab:blue\", label=\"x(t)\")\n",
    "ax.fill_between(time, x_lower, x_upper, color=\"tab:blue\", alpha=0.25, label='±1σ', ec=None)\n",
    "ax.set_xlabel('time [s]')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "\n",
    "It should be noted that this kind of uncertainty analysis using taylor approximations only really makes sense in linear systems or in nonlinear systems for small uncertainties (comparable to a small signal analysis, its still an approximation). Otherwise the linearization will not be sufficiently accurate. In the simple feedback system of our example, its not an issue however, because its inherently linear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}